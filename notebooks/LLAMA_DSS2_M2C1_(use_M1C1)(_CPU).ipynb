{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FPdwJ93rEsl"
      },
      "source": [
        "For the sentence types: [As expected, 'Afghan' people are so ---]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mDmXe9gPsSM"
      },
      "source": [
        "# **Importing Libraries and Modules and Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KIA-kyAPsSO",
        "outputId": "627994a0-c047-41a4-ac3e-0a15bba34bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pip in ./.local/lib/python3.10/site-packages (23.3.1)\n",
            "Collecting pip\n",
            "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.3.1\n",
            "    Uninstalling pip-23.3.1:\n",
            "      Successfully uninstalled pip-23.3.1\n",
            "Successfully installed pip-24.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformer-lens==1.12.0 in ./.local/lib/python3.10/site-packages (1.12.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (0.14.1)\n",
            "Requirement already satisfied: datasets>=2.7.1 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (3.0.1)\n",
            "Requirement already satisfied: einops>=0.6.0 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (0.7.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (0.2.34)\n",
            "Requirement already satisfied: numpy>=1.24 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/lib/python3/dist-packages (from transformer-lens==1.12.0) (1.3.5)\n",
            "Requirement already satisfied: rich>=12.6.0 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (13.9.2)\n",
            "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /usr/lib/python3/dist-packages (from transformer-lens==1.12.0) (2.0.1)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (4.66.5)\n",
            "Requirement already satisfied: transformers>=4.25.1 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (4.45.2)\n",
            "Requirement already satisfied: typing-extensions in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (4.8.0)\n",
            "Requirement already satisfied: wandb>=0.13.5 in ./.local/lib/python3.10/site-packages (from transformer-lens==1.12.0) (0.18.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from accelerate>=0.23.0->transformer-lens==1.12.0) (21.3)\n",
            "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate>=0.23.0->transformer-lens==1.12.0) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate>=0.23.0->transformer-lens==1.12.0) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==1.12.0) (0.25.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in ./.local/lib/python3.10/site-packages (from accelerate>=0.23.0->transformer-lens==1.12.0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets>=2.7.1->transformer-lens==1.12.0) (3.6.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==1.12.0) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==1.12.0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==1.12.0) (2.32.3)\n",
            "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==1.12.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==1.12.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in ./.local/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.7.1->transformer-lens==1.12.0) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==1.12.0) (3.10.10)\n",
            "Requirement already satisfied: typeguard==2.13.3 in ./.local/lib/python3.10/site-packages (from jaxtyping>=0.2.11->transformer-lens==1.12.0) (2.13.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.local/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==1.12.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.local/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==1.12.0) (2.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers>=4.25.1->transformer-lens==1.12.0) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.local/lib/python3.10/site-packages (from transformers>=4.25.1->transformer-lens==1.12.0) (0.20.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (8.0.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (2.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (4.21.12)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in ./.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (2.16.0)\n",
            "Requirement already satisfied: setproctitle in ./.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer-lens==1.12.0) (59.6.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==1.12.0) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==1.12.0) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==1.12.0) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==1.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==1.12.0) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==1.12.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer-lens==1.12.0) (2020.6.20)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==1.12.0) (5.0.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.7.1->transformer-lens==1.12.0) (0.2.0)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
            "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pygraphviz\n",
            "  Using cached pygraphviz-1.14.tar.gz (106 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pygraphviz: filename=pygraphviz-1.14-cp310-cp310-linux_x86_64.whl size=168634 sha256=c06a9be491e2bbc7207b723519ba1a8f9456074b7cc463870adae3b232102344\n",
            "  Stored in directory: /home/ubuntu/.cache/pip/wheels/61/ab/cd/e24a22c32830b8b4948c8887d8714d399f0f806f206a034698\n",
            "Successfully built pygraphviz\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.14\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: cmapy in ./.local/lib/python3.10/site-packages (0.6.6)\n",
            "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from cmapy) (3.5.1)\n",
            "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from cmapy) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=3.3 in ./.local/lib/python3.10/site-packages (from cmapy) (4.10.0.84)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Cloning into 'EAP-positional'...\n",
            "remote: Enumerating objects: 391, done.\u001b[K\n",
            "remote: Counting objects: 100% (171/171), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 391 (delta 95), reused 121 (delta 59), pack-reused 220 (from 1)\u001b[K\n",
            "Receiving objects: 100% (391/391), 162.57 KiB | 1.85 MiB/s, done.\n",
            "Resolving deltas: 100% (231/231), done.\n",
            "--2024-10-15 15:12:05--  https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./main/Nationalities.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2571 (2.5K) [text/plain]\n",
            "Saving to: ‘Nationalities.csv’\n",
            "\n",
            "Nationalities.csv   100%[===================>]   2.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-15 15:12:05 (14.4 MB/s) - ‘Nationalities.csv’ saved [2571/2571]\n",
            "\n",
            "/home/ubuntu/EAP-positional\n",
            "Branch 'tutorial' set up to track remote branch 'tutorial' from 'origin'.\n",
            "Switched to a new branch 'tutorial'\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Obtaining file:///home/ubuntu/EAP-positional\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[?25hInstalling collected packages: eap\n",
            "\u001b[33m  DEPRECATION: Legacy editable install of eap==0.1.0 from file:///home/ubuntu/EAP-positional (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py develop for eap\n",
            "Successfully installed eap\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "/home/ubuntu\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting plotly\n",
            "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting tenacity>=6.2.0 (from plotly)\n",
            "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from plotly) (21.3)\n",
            "Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: tenacity, plotly\n",
            "Successfully installed plotly-5.24.1 tenacity-9.0.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in ./.local/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.25.2)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: jaxtyping in ./.local/lib/python3.10/site-packages (0.2.34)\n",
            "Requirement already satisfied: typeguard==2.13.3 in ./.local/lib/python3.10/site-packages (from jaxtyping) (2.13.3)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: better_abc in ./.local/lib/python3.10/site-packages (0.0.3)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: fancy_einsum in ./.local/lib/python3.10/site-packages (0.0.3)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: wandb in ./.local/lib/python3.10/site-packages (0.18.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb) (8.0.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.local/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/lib/python3/dist-packages (from wandb) (2.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/lib/python3/dist-packages (from wandb) (4.21.12)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/lib/python3/dist-packages (from wandb) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in ./.local/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in ./.local/lib/python3.10/site-packages (from wandb) (2.16.0)\n",
            "Requirement already satisfied: setproctitle in ./.local/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb) (59.6.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2020.6.20)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in ./.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: einops==0.7.0 in ./.local/lib/python3.10/site-packages (0.7.0)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (0.2.0)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.45.2)\n",
            "Requirement already satisfied: huggingface_hub in ./.local/lib/python3.10/site-packages (0.25.2)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in ./.local/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./.local/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface_hub) (4.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
            "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "\u001b[33mWARNING: Error parsing dependencies of flatbuffers: Invalid version: '1.12.1-git20200711.33e2d80-dfsg1-0.6'\u001b[0m\u001b[33m\n",
            "\u001b[0mE: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
            "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip\n",
        "import sys, os\n",
        "%pip install transformer-lens==1.12.0\n",
        "!apt install -y graphviz\n",
        "!apt install libgraphviz-dev\n",
        "%pip install pygraphviz\n",
        "%pip install cmapy\n",
        "!git clone https://github.com/hannamw/EAP-positional.git\n",
        "!wget https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./main/Nationalities.csv\n",
        "%cd EAP-positional\n",
        "!git checkout tutorial\n",
        "%pip install -e .\n",
        "sys.path.append(os.getcwd())\n",
        "%cd ..\n",
        "\n",
        "!pip install plotly\n",
        "!pip install datasets\n",
        "!pip install jaxtyping\n",
        "!pip install better_abc\n",
        "!pip install fancy_einsum\n",
        "!pip install wandb\n",
        "!pip install einops==0.7.0\n",
        "!pip install sentencepiece\n",
        "\n",
        "!pip install datasets transformers huggingface_hub\n",
        "!apt-get install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIuEk_ldPsSO",
        "outputId": "7463d5d3-19d5-4f3a-8bbd-14e83f09d132"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import plotly.express as px\n",
        "\n",
        "from typing import List, Union, Optional, Tuple, Literal, Callable\n",
        "from functools import partial\n",
        "from IPython.display import Image, display\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, ActivationCache\n",
        "import plotly.io as pio\n",
        "\n",
        "from transformers import pipeline\n",
        "from pprint import pprint\n",
        "from einops import einsum\n",
        "\n",
        "#pio.renderers.default = \"colab\"\n",
        "\n",
        "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#if not torch.cuda.is_available():\n",
        "#    print(\"WARNING: Running on CPU. Did you remember to set your Colab accelerator to GPU?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjDkvoDuPsSP"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfFolder\n",
        "\n",
        "HfFolder.save_token(\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_2HDIfWPsSP"
      },
      "outputs": [],
      "source": [
        "from transformers import LlamaForCausalLM, LlamaTokenizerFast\n",
        "model_name = 'meta-llama/Llama-2-7b-hf'\n",
        "tokenizer = LlamaTokenizerFast.from_pretrained(model_name)\n",
        "tokenizer.add_bos_token = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "da266dceacba49b8abcb6b1b2153ea12",
            "b43e46f388714693b7d24de2de5dcdcf",
            "ae96b226ac07451b8b4ed7a5cb16d0be",
            "a30bd580c8194a1d8926235c22c88443",
            "64365466073e4ef7bfeb967a7bd1ab49",
            "b89817ea08f94c8791fe746ad9fe504a",
            "7a8b788481d049af88271c522f0d7fd1",
            "646c8dd678184249878d125be12e495f",
            "24de86c8724d41839693669c26abf77f",
            "84fa299c340a4c00a10662baa471becc",
            "c31f892e51704927b18fe0ffa0dff9ce",
            "fff625c8dea34b76abed1018534a2cf0",
            "456dd97d142c42e1ac37b711c20e97b3",
            "da241dbe4b55414382d13a68a4d96096",
            "f383df1057454428b9187ee7ea534e17",
            "960beee0b7fb4f468ab8f459296cf93a",
            "61e67ef7143845369df620f2d0e24a56",
            "efd7e6684cad45ef920c7abc678618ce",
            "1bd3742056e54e75bbda53e67688b4cb",
            "1c9f84ddd57c4a13a9074aa50687f8ed",
            "590fd29c1d8243f0a419d313b4047d27",
            "31bf0065ea6c4ae9b02d011c19e16c8f",
            "947cd35bada548da8cc7201b17c068fd",
            "5741f9a5f06d4373b40ddb1673c521ad",
            "90bf52b64a76412799248a5f82dbb0f7",
            "45359e55431e46b79038751d0d4b15e7"
          ]
        },
        "id": "Rr_YPbLQPsSP",
        "outputId": "0e6deb9b-c7cb-4a25-92d3-f3dd7d09ffb6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45359e55431e46b79038751d0d4b15e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Cannot fold in layer norm, normalization_type is not LN.\n",
            "WARNING:root:You are not using LayerNorm, so the layer norm weights can't be folded! Skipping\n",
            "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model meta-llama/Llama-2-7b-hf into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "hf_model = LlamaForCausalLM.from_pretrained(model_name).to('cpu')\n",
        "model = HookedTransformer.from_pretrained(\n",
        "    model_name,\n",
        "    hf_model=hf_model,\n",
        "    #n_devices=2,\n",
        "    device='cpu',\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "#model = model.to('cuda')\n",
        "model.cfg.use_attn_in = True\n",
        "model.cfg.use_split_qkv_input = True\n",
        "model.cfg.use_attn_result = True\n",
        "model.cfg.use_hook_mlp_in = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ1axhdxPsSQ"
      },
      "source": [
        "# **Reading and Modifying Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApQ_uB_tPsSQ"
      },
      "outputs": [],
      "source": [
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    device='cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYJ6rRlPPsSR"
      },
      "outputs": [],
      "source": [
        "def text_to_sentiment(sentence):\n",
        "  result = sentiment_pipeline(sentence)[0]\n",
        "  if result['label'] == \"POSITIVE\": return result['score']\n",
        "  if result['label'] == \"NEGATIVE\": return -result['score']\n",
        "  raise ValueError(\"Unknown result label: \" + result['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZbf20C9PsSR",
        "outputId": "7a487cca-9fc9-4474-acf1-5699e020aa66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-15 15:16:23--  https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./refs/heads/main/llama_dss_two_positive_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15894 (16K) [text/plain]\n",
            "Saving to: ‘llama_dss_two_positive_dataset.csv’\n",
            "\n",
            "llama_dss_two_posit 100%[===================>]  15.52K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-10-15 15:16:23 (19.1 MB/s) - ‘llama_dss_two_positive_dataset.csv’ saved [15894/15894]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-15 15:16:26--  https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./refs/heads/main/llama_dss_two_negative_dataset.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 592 [text/plain]\n",
            "Saving to: ‘llama_dss_two_negative_dataset.csv’\n",
            "\n",
            "llama_dss_two_negat 100%[===================>]     592  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-15 15:16:26 (50.2 MB/s) - ‘llama_dss_two_negative_dataset.csv’ saved [592/592]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./refs/heads/main/llama_dss_two_positive_dataset.csv\n",
        "!wget https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./refs/heads/main/llama_dss_two_negative_dataset.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRh5DbHsPsSR"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('llama_dss_two_positive_dataset.csv')\n",
        "df2 = pd.read_csv('llama_dss_two_negative_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeWcZnT2PsSS",
        "outputId": "05002d9d-9453-46b1-aab5-c76cf638c2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['As expected, Afghan people are so'], ['As expected, abc people are so'])\n",
            "(['As expected, American people are so'], ['As expected, abc people are so'])\n"
          ]
        }
      ],
      "source": [
        "def batch_dataset(df, batch_size=1):\n",
        "    sentence, corrupted = [df[col].tolist() for col in ['sentence', 'corrupted']]\n",
        "    sentence = [sentence[i:i+batch_size] for i in range(0, len(df), batch_size)]\n",
        "    corrupted = [corrupted[i:i+batch_size] for i in range(0, len(df), batch_size)]\n",
        "    return [(sentence[i], corrupted[i]) for i in range(len(sentence))]\n",
        "\n",
        "pos_dataset = batch_dataset(df1, batch_size=1)\n",
        "neg_dataset = batch_dataset(df2, batch_size=1)\n",
        "print(pos_dataset[0])\n",
        "print(neg_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_dti9v1PsSS"
      },
      "source": [
        "# **Evaluation funtions for circuit Finding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHiHHz5rPsSS"
      },
      "outputs": [],
      "source": [
        "import eap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxENjhKsPsSS"
      },
      "source": [
        "## **Graph module**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0NH8icHPsST"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Union, Tuple, Literal, Optional, Set\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import json\n",
        "import heapq\n",
        "\n",
        "import torch\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
        "import numpy as np\n",
        "import pygraphviz as pgv\n",
        "\n",
        "from eap.visualization import EDGE_TYPE_COLORS, generate_random_color\n",
        "\n",
        "class Node:\n",
        "    \"\"\"\n",
        "    A node in our computational graph. The in_hook is the TL hook into its inputs,\n",
        "    while the out_hook gets its outputs.\n",
        "    \"\"\"\n",
        "    name: str\n",
        "    layer: int\n",
        "    in_hook: str\n",
        "    out_hook: str\n",
        "    index: Tuple\n",
        "    parents: Set['Node']\n",
        "    parent_edges: Set['Edge']\n",
        "    children: Set['Node']\n",
        "    child_edges: Set['Edge']\n",
        "    in_graph: bool\n",
        "    qkv_inputs: Optional[List[str]]\n",
        "\n",
        "    def __init__(self, name: str, layer:int, in_hook: List[str], out_hook: str, index: Tuple, qkv_inputs: Optional[List[str]]=None):\n",
        "        self.name = name\n",
        "        self.layer = layer\n",
        "        self.in_hook = in_hook\n",
        "        self.out_hook = out_hook\n",
        "        self.index = index\n",
        "        self.in_graph = True\n",
        "        self.parents = set()\n",
        "        self.children = set()\n",
        "        self.parent_edges = set()\n",
        "        self.child_edges = set()\n",
        "        self.qkv_inputs = qkv_inputs\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.name == other.name\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Node({self.name})'\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.name)\n",
        "\n",
        "class LogitNode(Node):\n",
        "    def __init__(self, n_layers:int):\n",
        "        name = 'logits'\n",
        "        index = slice(None)\n",
        "        super().__init__(name, n_layers - 1, f\"blocks.{n_layers - 1}.hook_resid_post\", '', index)\n",
        "\n",
        "class MLPNode(Node):\n",
        "    def __init__(self, layer: int):\n",
        "        name = f'm{layer}'\n",
        "        index = slice(None)\n",
        "        super().__init__(name, layer, f\"blocks.{layer}.hook_mlp_in\", f\"blocks.{layer}.hook_mlp_out\", index)\n",
        "\n",
        "class AttentionNode(Node):\n",
        "    head: int\n",
        "    def __init__(self, layer:int, head:int):\n",
        "        name = f'a{layer}.h{head}'\n",
        "        self.head = head\n",
        "        index = (slice(None), slice(None), head)\n",
        "        super().__init__(name, layer, f'blocks.{layer}.hook_attn_in', f\"blocks.{layer}.attn.hook_result\", index, [f'blocks.{layer}.hook_{letter}_input' for letter in 'qkv'])\n",
        "\n",
        "class InputNode(Node):\n",
        "    def __init__(self):\n",
        "        name = 'input'\n",
        "        index = slice(None)\n",
        "        super().__init__(name, 0, '', \"blocks.0.hook_resid_pre\", index)\n",
        "\n",
        "class Edge:\n",
        "    name: str\n",
        "    parent: Node\n",
        "    child: Node\n",
        "    hook: str\n",
        "    index: Tuple\n",
        "    score : Optional[float]\n",
        "    in_graph: bool\n",
        "    def __init__(self, parent: Node, child: Node, qkv:Union[None, Literal['q'], Literal['k'], Literal['v']]=None):\n",
        "        self.name = f'{parent.name}->{child.name}' if qkv is None else f'{parent.name}->{child.name}<{qkv}>'\n",
        "        self.parent = parent\n",
        "        self.child = child\n",
        "        self.qkv = qkv\n",
        "        self.score = None\n",
        "        self.in_graph = True\n",
        "        if isinstance(child, AttentionNode):\n",
        "            if qkv is None:\n",
        "                raise ValueError(f'Edge({self.name}): Edges to attention heads must have a non-none value for qkv.')\n",
        "            self.hook = f'blocks.{child.layer}.hook_{qkv}_input'\n",
        "            self.index = (slice(None), slice(None), child.head)\n",
        "        else:\n",
        "            self.index = child.index\n",
        "            self.hook = child.in_hook\n",
        "    def get_color(self):\n",
        "        if self.qkv is not None:\n",
        "            return EDGE_TYPE_COLORS[self.qkv]\n",
        "        elif self.score < 0:\n",
        "            return \"#FF00FF\"\n",
        "        else:\n",
        "            return \"#000000\"\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.name == other.name\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Edge({self.name})'\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.name)\n",
        "\n",
        "class Graph:\n",
        "    nodes: Dict[str, Node]\n",
        "    edges: Dict[str, Edge]\n",
        "    n_forward: int\n",
        "    n_backward: int\n",
        "    cfg: HookedTransformerConfig\n",
        "\n",
        "    def __init__(self):\n",
        "        self.nodes = {}\n",
        "        self.edges = {}\n",
        "        self.n_forward = 0\n",
        "        self.n_backward = 0\n",
        "\n",
        "    def add_edge(self, parent:Node, child:Node, qkv:Union[None, Literal['q'], Literal['k'], Literal['v']]=None):\n",
        "        edge = Edge(parent, child, qkv)\n",
        "        self.edges[edge.name] = edge\n",
        "        parent.children.add(child)\n",
        "        parent.child_edges.add(edge)\n",
        "        child.parents.add(parent)\n",
        "        child.parent_edges.add(edge)\n",
        "\n",
        "    def forward_index(self, node:Node, attn_slice=True):\n",
        "        if isinstance(node, InputNode):\n",
        "            return 0\n",
        "        elif isinstance(node, LogitNode):\n",
        "            return self.n_forward\n",
        "            # raise ValueError(f\"No forward for logits node\")\n",
        "        elif isinstance(node, MLPNode):\n",
        "            return 1 + node.layer * (self.cfg['n_heads'] + 1) + self.cfg['n_heads']\n",
        "        elif isinstance(node, AttentionNode):\n",
        "            i =  1 + node.layer * (self.cfg['n_heads'] + 1)\n",
        "            return slice(i, i + self.cfg['n_heads']) if attn_slice else i + node.head\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid node: {node} of type {type(node)}\")\n",
        "\n",
        "\n",
        "    def backward_index(self, node:Node, qkv=None, attn_slice=True):\n",
        "        if isinstance(node, InputNode):\n",
        "            raise ValueError(f\"No backward for input node\")\n",
        "        elif isinstance(node, LogitNode):\n",
        "            return -1\n",
        "        elif isinstance(node, MLPNode):\n",
        "            return (node.layer) * (3 * self.cfg['n_heads'] + 1) + 3 * self.cfg['n_heads']\n",
        "        elif isinstance(node, AttentionNode):\n",
        "            assert qkv in 'qkv', f'Must give qkv for AttentionNode, but got {qkv}'\n",
        "            i = node.layer * (3 * self.cfg['n_heads'] + 1) + ('qkv'.index(qkv) * self.cfg['n_heads'])\n",
        "            return slice(i, i + self.cfg['n_heads']) if attn_slice else i + node.head\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid node: {node} of type {type(node)}\")\n",
        "\n",
        "    def scores(self, absolute=False, nonzero=False, in_graph=False, sort=True):\n",
        "        s = [edge.score for edge in self.edges.values() if edge.score != 0 and (edge.in_graph or not in_graph)] if nonzero else [edge.score for edge in self.edges.values()]\n",
        "        s = torch.tensor(s)\n",
        "        if absolute:\n",
        "            s = s.abs()\n",
        "        return torch.sort(s).values if sort else s\n",
        "\n",
        "    def count_included_edges(self):\n",
        "        return sum(edge.in_graph for edge in self.edges.values())\n",
        "\n",
        "    def count_included_nodes(self):\n",
        "        return sum(node.in_graph for node in self.nodes.values())\n",
        "\n",
        "    def apply_threshold(self, threshold: float, absolute: bool):\n",
        "        threshold = float(threshold)\n",
        "        for node in self.nodes.values():\n",
        "            node.in_graph = True\n",
        "\n",
        "        for edge in self.edges.values():\n",
        "            edge.in_graph = abs(edge.score) <= threshold if absolute else edge.score <= threshold\n",
        "\n",
        "    def apply_greedy(self, n_edges, reset=True, absolute: bool=False):\n",
        "        if reset:\n",
        "            for node in self.nodes.values():\n",
        "                node.in_graph = False\n",
        "            for edge in self.edges.values():\n",
        "                edge.in_graph = False\n",
        "            self.nodes['logits'].in_graph = True\n",
        "\n",
        "        def abs_id(s: float):\n",
        "            return abs(s) if absolute else s\n",
        "\n",
        "        candidate_edges = sorted([edge for edge in self.edges.values() if edge.child.in_graph], key = lambda edge: abs_id(edge.score), reverse=True)\n",
        "\n",
        "        edges = heapq.merge(candidate_edges, key = lambda edge: abs_id(edge.score), reverse=True)\n",
        "        while n_edges > 0:\n",
        "            n_edges -= 1\n",
        "            top_edge = next(edges)\n",
        "            top_edge.in_graph = True\n",
        "            parent = top_edge.parent\n",
        "            if not parent.in_graph:\n",
        "                parent.in_graph = True\n",
        "                parent_parent_edges = sorted([parent_edge for parent_edge in parent.parent_edges], key = lambda edge: abs_id(edge.score), reverse=True)\n",
        "                edges = heapq.merge(edges, parent_parent_edges, key = lambda edge: abs_id(edge.score), reverse=True)\n",
        "\n",
        "    def prune_dead_nodes(self, prune_childless=True, prune_parentless=True):\n",
        "        self.nodes['logits'].in_graph = any(parent_edge.in_graph for parent_edge in self.nodes['logits'].parent_edges)\n",
        "\n",
        "        for node in reversed(self.nodes.values()):\n",
        "            if isinstance(node, LogitNode):\n",
        "                continue\n",
        "\n",
        "            if any(child_edge.in_graph for child_edge in node.child_edges) :\n",
        "                node.in_graph = True\n",
        "            else:\n",
        "                if prune_childless:\n",
        "                    node.in_graph = False\n",
        "                    for parent_edge in node.parent_edges:\n",
        "                        parent_edge.in_graph = False\n",
        "                else:\n",
        "                    if any(child_edge.in_graph for child_edge in node.child_edges):\n",
        "                        node.in_graph = True\n",
        "                    else:\n",
        "                        node.in_graph = False\n",
        "\n",
        "        if prune_parentless:\n",
        "            for node in self.nodes.values():\n",
        "                if not isinstance(node, InputNode) and node.in_graph and not any(parent_edge.in_graph for parent_edge in node.parent_edges):\n",
        "                    node.in_graph = False\n",
        "                    for child_edge in node.child_edges:\n",
        "                        child_edge.in_graph = False\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_model(cls, model_or_config: Union[HookedTransformer,HookedTransformerConfig, Dict]):\n",
        "        graph = Graph()\n",
        "        if isinstance(model_or_config, HookedTransformer):\n",
        "            cfg = model_or_config.cfg\n",
        "            graph.cfg = {'n_layers': cfg.n_layers, 'n_heads': cfg.n_heads, 'parallel_attn_mlp':cfg.parallel_attn_mlp}\n",
        "        elif isinstance(model_or_config, HookedTransformerConfig):\n",
        "            cfg = model_or_config\n",
        "            graph.cfg = {'n_layers': cfg.n_layers, 'n_heads': cfg.n_heads, 'parallel_attn_mlp':cfg.parallel_attn_mlp}\n",
        "        else:\n",
        "            graph.cfg = model_or_config\n",
        "\n",
        "        input_node = InputNode()\n",
        "        graph.nodes[input_node.name] = input_node\n",
        "        residual_stream = [input_node]\n",
        "\n",
        "        for layer in range(graph.cfg['n_layers']):\n",
        "            attn_nodes = [AttentionNode(layer, head) for head in range(graph.cfg['n_heads'])]\n",
        "            mlp_node = MLPNode(layer)\n",
        "\n",
        "            for attn_node in attn_nodes:\n",
        "                graph.nodes[attn_node.name] = attn_node\n",
        "            graph.nodes[mlp_node.name] = mlp_node\n",
        "\n",
        "            if graph.cfg['parallel_attn_mlp']:\n",
        "                for node in residual_stream:\n",
        "                    for attn_node in attn_nodes:\n",
        "                        for letter in 'qkv':\n",
        "                            graph.add_edge(node, attn_node, qkv=letter)\n",
        "                    graph.add_edge(node, mlp_node)\n",
        "\n",
        "                residual_stream += attn_nodes\n",
        "                residual_stream.append(mlp_node)\n",
        "\n",
        "            else:\n",
        "                for node in residual_stream:\n",
        "                    for attn_node in attn_nodes:\n",
        "                        for letter in 'qkv':\n",
        "                            graph.add_edge(node, attn_node, qkv=letter)\n",
        "                residual_stream += attn_nodes\n",
        "\n",
        "                for node in residual_stream:\n",
        "                    graph.add_edge(node, mlp_node)\n",
        "                residual_stream.append(mlp_node)\n",
        "\n",
        "        logit_node = LogitNode(graph.cfg['n_layers'])\n",
        "        for node in residual_stream:\n",
        "            graph.add_edge(node, logit_node)\n",
        "\n",
        "        graph.nodes[logit_node.name] = logit_node\n",
        "\n",
        "        graph.n_forward = 1 + graph.cfg['n_layers'] * (graph.cfg['n_heads'] + 1)\n",
        "        graph.n_backward = graph.cfg['n_layers'] * (3 * graph.cfg['n_heads'] + 1) + 1\n",
        "\n",
        "        return graph\n",
        "\n",
        "\n",
        "    def to_json(self, filename):\n",
        "        # non serializable info\n",
        "        d = {'cfg':self.cfg, 'nodes': {str(name): bool(node.in_graph) for name, node in self.nodes.items()}, 'edges':{str(name): {'score': float(edge.score), 'in_graph': bool(edge.in_graph)} for name, edge in self.edges.items()}}\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(d, f)\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            d = json.load(f)\n",
        "        g = Graph.from_model(d['cfg'])\n",
        "        for name, in_graph in d['nodes'].items():\n",
        "            g.nodes[name].in_graph = in_graph\n",
        "\n",
        "        for name, info in d['edges'].items():\n",
        "            g.edges[name].score = info['score']\n",
        "            g.edges[name].in_graph = info['in_graph']\n",
        "\n",
        "        return g\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        keys_equal = (set(self.nodes.keys()) == set(other.nodes.keys())) and (set(self.edges.keys()) == set(other.edges.keys()))\n",
        "        if not keys_equal:\n",
        "            return False\n",
        "\n",
        "        for name, node in self.nodes.items():\n",
        "            if node.in_graph != other.nodes[name].in_graph:\n",
        "                return False\n",
        "\n",
        "        for name, edge in self.edges.items():\n",
        "            if (edge.in_graph != other.edges[name].in_graph) or not np.allclose(edge.score, other.edges[name].score):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def to_graphviz(\n",
        "        self,\n",
        "        colorscheme: str = \"Pastel2\",\n",
        "        minimum_penwidth: float = 0.3,\n",
        "        layout: str=\"dot\",\n",
        "        seed: Optional[int] = None\n",
        "    ) -> pgv.AGraph:\n",
        "        \"\"\"\n",
        "        Colorscheme: a cmap colorscheme\n",
        "        \"\"\"\n",
        "        g = pgv.AGraph(directed=True, bgcolor=\"white\", overlap=\"false\", splines=\"true\", layout=layout)\n",
        "\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        #colors = {node.name: generate_random_color(colorscheme) for node in self.nodes.values()}\n",
        "\n",
        "        for node in self.nodes.values():\n",
        "            if node.in_graph:\n",
        "                if node.name in {'input'}:\n",
        "                  clr='yellowgreen'\n",
        "                elif node.name in {'logits'}:\n",
        "                  clr='gold'\n",
        "                elif node.name in {'m0', 'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11'}:\n",
        "                  clr = 'plum'\n",
        "                else:\n",
        "                  clr='sandybrown'\n",
        "                g.add_node(node.name,\n",
        "                        fillcolor=clr,\n",
        "                        color=\"black\",\n",
        "                        style=\"filled, rounded\",\n",
        "                        shape=\"box\",\n",
        "                        fontname=\"Helvetica\",\n",
        "                        )\n",
        "\n",
        "        for edge in self.edges.values():\n",
        "            if edge.in_graph:\n",
        "                score = 0 if edge.score is None else edge.score\n",
        "                g.add_edge(edge.parent.name,\n",
        "                        edge.child.name,\n",
        "                        penwidth=str(max(minimum_penwidth, score) * 2),\n",
        "                        color='black',\n",
        "                        )\n",
        "        return g\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z5mQw0CPsSU"
      },
      "source": [
        "## **Rest of the functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0luUjmEPsSU"
      },
      "outputs": [],
      "source": [
        "g = Graph.from_model(model)\n",
        "g1 = Graph.from_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVEHQonzPsSU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prob_diff(sentence, logits: torch.Tensor, loss=False, mean=False):\n",
        "    Positive_Probs = 0\n",
        "    Negative_Probs = 0\n",
        "    k=10\n",
        "    probs = torch.softmax(logits[:,-1], dim=-1)\n",
        "    probs, next_tokens = torch.topk(probs[-1], k)\n",
        "    results = []\n",
        "    for i, (prob, token_id) in enumerate(zip(probs,next_tokens)):\n",
        "        token = model.tokenizer.decode(token_id.item())\n",
        "        predicted = sentence[0] + \" \" + token  # Append the predicted token to the current text\n",
        "        Senti_Scores = text_to_sentiment(predicted)\n",
        "        if Senti_Scores >= 0:\n",
        "          Positive_Probs += prob.sum()\n",
        "        else:\n",
        "          Negative_Probs += prob.sum()\n",
        "\n",
        "    results.append(Positive_Probs - Negative_Probs)\n",
        "    results = torch.stack(results)\n",
        "    if loss:\n",
        "        results = -results\n",
        "    if mean:\n",
        "        results = results.mean()\n",
        "    return results\n",
        "\n",
        "metric = prob_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzoLrSblPsSV"
      },
      "outputs": [],
      "source": [
        "# trying a new metric as the sum of only probabilities of positive tokens\n",
        "def prob_diff_new(sentence, logits: torch.Tensor, loss=False, mean=False):\n",
        "    #Positive_Probs = torch.tensor(0, dtype=torch.float32, device='cuda')\n",
        "    Positive_Probs = 0\n",
        "    Negative_Probs = 0\n",
        "    k=10\n",
        "    probs = torch.softmax(logits[:,-1], dim=-1)\n",
        "    probs, next_tokens = torch.topk(probs[-1], k)\n",
        "    results = []\n",
        "    for i, (prob, token_id) in enumerate(zip(probs,next_tokens)):\n",
        "        token = model.tokenizer.decode(token_id.item())\n",
        "        predicted = sentence[0] + \" \" + token  # Append the predicted token to the current text\n",
        "        Senti_Scores = text_to_sentiment(predicted)\n",
        "        if Senti_Scores >= 0:\n",
        "          Positive_Probs += prob.sum()\n",
        "        else:\n",
        "          Negative_Probs += (prob-prob).sum()\n",
        "\n",
        "    results.append(Positive_Probs - Negative_Probs)\n",
        "    results = torch.stack(results)\n",
        "    if loss:\n",
        "        results = -results\n",
        "    if mean:\n",
        "        results = results.mean()\n",
        "    return results\n",
        "\n",
        "#metric = prob_diff_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhKbaFYqPsSV"
      },
      "outputs": [],
      "source": [
        "def evaluate_baseline(model: HookedTransformer, dataset, metrics: List[Callable[[Tensor], Tensor]]):\n",
        "    metrics_list = True\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "        metrics_list = False\n",
        "\n",
        "    results = [[] for _ in metrics]\n",
        "    for sentence, corrupted in tqdm(dataset):\n",
        "        with torch.inference_mode():\n",
        "            logits = model(sentence)\n",
        "        for j, metric in enumerate(metrics):\n",
        "            r = metric(sentence,logits).cpu()\n",
        "            if len(r.size()) == 0:\n",
        "                r = r.unsqueeze(0)\n",
        "            results[j].append(r)\n",
        "    results = [torch.cat(rs) for rs in results]\n",
        "    if not metrics_list:\n",
        "        results = results[0]\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEJbsPgpPsSV"
      },
      "outputs": [],
      "source": [
        "def evaluate_graph(model: HookedTransformer, graph: Graph, dataset, metrics: List[Callable[[Tensor], Tensor]], prune:bool=True):\n",
        "    \"\"\"\n",
        "    Evaluate a circuit (i.e. a graph where only some nodes are false, probably created by calling graph.apply_threshold). You probably want to prune beforehand to make sure your circuit is valid.\n",
        "    \"\"\"\n",
        "    # Pruning the Graph: If prune is True, it prunes the graph by removing childless and parentless nodes.\n",
        "    if prune:\n",
        "        graph.prune_dead_nodes(prune_childless=True, prune_parentless=True)\n",
        "\n",
        "    # Check for Empty Circuit: Sets empty_circuit to True if the 'logits' node is not in the graph.\n",
        "    empty_circuit = not graph.nodes['logits'].in_graph\n",
        "\n",
        "    # Forward Hook Names: Collects the output hooks of parent nodes from all edges in the graph.\n",
        "    # Forward Filter: Creates a filter function to check if a given hook name is in fwd_names.\n",
        "    fwd_names = {edge.parent.out_hook for edge in graph.edges.values()}\n",
        "    fwd_filter = lambda x: x in fwd_names\n",
        "\n",
        "    # Get Caching Hooks: Retrieves the corrupted and mixed forward caches and hooks from the model using the forward filter.\n",
        "    corrupted_fwd_cache, corrupted_fwd_hooks, _ = model.get_caching_hooks(fwd_filter)\n",
        "    mixed_fwd_cache, mixed_fwd_hooks, _ = model.get_caching_hooks(fwd_filter)\n",
        "\n",
        "    # Nodes in Graph: Collects all nodes in the graph that are not of type InputNode and are part of the graph (in_graph is True).\n",
        "    nodes_in_graph = [node for node in graph.nodes.values() if node.in_graph if not isinstance(node, InputNode)]\n",
        "\n",
        "    \"\"\"For each node in the graph, construct its input (in the case of attention heads, multiple inputs) by corrupting the incoming edges that are not in the circuit.\n",
        "       We assume that the corrupted cache is filled with corresponding corrupted activations, and that the mixed cache contains the computed activations from preceding nodes in this forward pass.\"\"\"\n",
        "    # Input Construction Hook: Defines a nested function make_input_construction_hook that creates an input_construction_hook.\n",
        "    # Inner Function input_construction_hook: Iterates over the parent edges of a node.\n",
        "    # If the qkv attribute of an edge does not match the provided qkv parameter, it skips the edge.\n",
        "    # If the edge is not part of the graph (in_graph is False), it modifies the activations by replacing values from the mixed forward cache with those from the corrupted forward cache.\n",
        "    # Return: Returns the input_construction_hook function.\n",
        "    def make_input_construction_hook(node: Node, qkv=None):\n",
        "        def input_construction_hook(activations, hook):\n",
        "            for edge in node.parent_edges:\n",
        "                if edge.qkv != qkv:\n",
        "                    continue\n",
        "\n",
        "                parent:Node = edge.parent\n",
        "                if not edge.in_graph:\n",
        "                    activations[edge.index] -= mixed_fwd_cache[parent.out_hook][parent.index]\n",
        "                    activations[edge.index] += corrupted_fwd_cache[parent.out_hook][parent.index]\n",
        "            return activations\n",
        "        return input_construction_hook\n",
        "\n",
        "    # Create Input Construction Hooks: Iterates over the nodes in the graph to create input construction hooks.\n",
        "    # InputNode: Skips if the node is an InputNode.\n",
        "    # LogitNode or MLPNode: Adds a hook using make_input_construction_hook without qkv.\n",
        "    # AttentionNode: Adds hooks for each of 'q', 'k', and 'v' inputs.\n",
        "    # Invalid Node: Raises an error if the node type is not recognized.\n",
        "    input_construction_hooks = []\n",
        "    for node in nodes_in_graph:\n",
        "        if isinstance(node, InputNode):\n",
        "            pass\n",
        "        elif isinstance(node, LogitNode) or isinstance(node, MLPNode):\n",
        "            input_construction_hooks.append((node.in_hook, make_input_construction_hook(node)))\n",
        "        elif isinstance(node, AttentionNode):\n",
        "            for i, letter in enumerate('qkv'):\n",
        "                input_construction_hooks.append((node.qkv_inputs[i], make_input_construction_hook(node, qkv=letter)))\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid node: {node} of type {type(node)}\")\n",
        "\n",
        "    # and here we actually run / evaluate the model\n",
        "    metrics_list = True\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "        metrics_list = False\n",
        "    results = [[] for _ in metrics]\n",
        "\n",
        "    for sentence, corrupted in tqdm(dataset):\n",
        "        sens = [sentence, corrupted]\n",
        "        sens = [str(s) for s in sens]\n",
        "        max_length = max(len(model.tokenizer.tokenize(s, add_special_tokens=False)) for s in sens)\n",
        "        padded_sentences = [model.tokenizer.encode(s, padding='max_length', max_length=max_length, return_tensors='pt', add_special_tokens=False) for s in sens]\n",
        "        s1 = padded_sentences[0]\n",
        "        s2 = padded_sentences[1]\n",
        "        clean = model.tokenizer.decode(s1[0])\n",
        "        corrupted_dash = model.tokenizer.decode(s2[0])\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            with model.hooks(corrupted_fwd_hooks):\n",
        "                corrupted_logits = model(corrupted_dash)\n",
        "\n",
        "            with model.hooks(mixed_fwd_hooks + input_construction_hooks):\n",
        "                if empty_circuit:\n",
        "                    # if the circuit is totally empty, so is nodes_in_graph\n",
        "                    # so we just corrupt everything manually like this\n",
        "                    logits = model(corrupted_dash)\n",
        "                else:\n",
        "                    logits = model(clean)\n",
        "        for i, metric in enumerate(metrics):\n",
        "            r = metric(sentence,logits).cpu()\n",
        "            if len(r.size()) == 0:\n",
        "                r = r.unsqueeze(0)\n",
        "            results[i].append(r)\n",
        "\n",
        "    results = [torch.cat(rs) for rs in results]\n",
        "    if not metrics_list:\n",
        "        results = results[0]\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87czaKK3PsSW"
      },
      "source": [
        "# **Edge Attribution Patching**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__DGxOsLPsSW"
      },
      "source": [
        "## **EAP Attribute Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf8RUt7sPsSX"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "def get_npos_input_lengths(model, inputs):\n",
        "    tokenized = model.tokenizer(inputs, padding='longest', return_tensors='pt', add_special_tokens=True)\n",
        "    n_pos = 1 + tokenized.attention_mask.size(1)\n",
        "    input_lengths = 1 + tokenized.attention_mask.sum(1)\n",
        "    return n_pos, input_lengths\n",
        "\n",
        "def make_hooks_and_matrices(model: HookedTransformer, graph: Graph, batch_size:int , n_pos:int, scores):\n",
        "    activation_difference = torch.zeros((batch_size, n_pos, graph.n_forward, model.cfg.d_model), device=device, dtype=model.cfg.dtype)\n",
        "\n",
        "    processed_attn_layers = set()\n",
        "    fwd_hooks_clean = []\n",
        "    fwd_hooks_corrupted = []\n",
        "    bwd_hooks = []\n",
        "\n",
        "    def activation_hook(index, activations, hook, add:bool=True):\n",
        "        acts = activations.detach()\n",
        "        if not add:\n",
        "            acts = -acts\n",
        "        try:\n",
        "            activation_difference[:, :, index] += acts\n",
        "        except RuntimeError as e:\n",
        "            print(hook.name, activation_difference[:, :, index].size(), acts.size())\n",
        "            raise e\n",
        "\n",
        "    def gradient_hook(fwd_index: Union[slice, int], bwd_index: Union[slice, int], gradients:torch.Tensor, hook):\n",
        "        grads = gradients.detach()\n",
        "        try:\n",
        "            if isinstance(fwd_index, slice):\n",
        "                fwd_index = fwd_index.start\n",
        "            if grads.ndim == 3:\n",
        "                grads = grads.unsqueeze(2)\n",
        "            s = einsum(activation_difference[:, :, :fwd_index], grads,'batch pos forward hidden, batch pos backward hidden -> forward backward')\n",
        "            s = s.squeeze(1)\n",
        "            scores[:fwd_index, bwd_index] += s\n",
        "        except RuntimeError as e:\n",
        "            print(hook.name, activation_difference.size(), grads.size())\n",
        "            raise e\n",
        "\n",
        "    for name, node in graph.nodes.items():\n",
        "        if isinstance(node, AttentionNode):\n",
        "            if node.layer in processed_attn_layers:\n",
        "                continue\n",
        "            else:\n",
        "                processed_attn_layers.add(node.layer)\n",
        "\n",
        "        # exclude logits from forward\n",
        "        fwd_index =  graph.forward_index(node)\n",
        "        if not isinstance(node, LogitNode):\n",
        "            fwd_hooks_corrupted.append((node.out_hook, partial(activation_hook, fwd_index)))\n",
        "            fwd_hooks_clean.append((node.out_hook, partial(activation_hook, fwd_index, add=False)))\n",
        "        if not isinstance(node, InputNode):\n",
        "            if isinstance(node, AttentionNode):\n",
        "                for i, letter in enumerate('qkv'):\n",
        "                    bwd_index = graph.backward_index(node, qkv=letter)\n",
        "                    bwd_hooks.append((node.qkv_inputs[i], partial(gradient_hook, fwd_index, bwd_index)))\n",
        "            else:\n",
        "                bwd_index = graph.backward_index(node)\n",
        "                bwd_hooks.append((node.in_hook, partial(gradient_hook, fwd_index, bwd_index)))\n",
        "\n",
        "    return (fwd_hooks_corrupted, fwd_hooks_clean, bwd_hooks), activation_difference\n",
        "\n",
        "######                #######\n",
        "#####  Edit from here  #######\n",
        "#####                 #######\n",
        "\n",
        "def get_scores(model: HookedTransformer, graph: Graph, dataset, metric: Callable[[Tensor], Tensor]):\n",
        "    scores = torch.zeros((graph.n_forward, graph.n_backward), device=device, dtype=model.cfg.dtype)\n",
        "\n",
        "    total_items = 0\n",
        "    for sentence, corrupted in tqdm(dataset):\n",
        "        sens = [sentence, corrupted]\n",
        "        sens = [str(s) for s in sens]\n",
        "        max_length = max(len(model.tokenizer.tokenize(s)) for s in sens)\n",
        "        padded_sentences = [model.tokenizer.encode(s, padding='max_length', max_length=max_length, return_tensors='pt', add_special_tokens=True) for s in sens]\n",
        "        s1 = padded_sentences[0]\n",
        "        s2 = padded_sentences[1]\n",
        "        clean = model.tokenizer.decode(s1[0])\n",
        "        corrupted_dash = model.tokenizer.decode(s2[0])\n",
        "\n",
        "        batch_size = len(clean)\n",
        "        total_items += batch_size\n",
        "        n_pos, input_lengths = get_npos_input_lengths(model, clean)\n",
        "\n",
        "        (fwd_hooks_corrupted, fwd_hooks_clean, bwd_hooks), activation_difference = make_hooks_and_matrices(model, graph, batch_size, n_pos, scores)\n",
        "\n",
        "        with model.hooks(fwd_hooks=fwd_hooks_corrupted):\n",
        "            corrupted_logits = model(corrupted_dash)\n",
        "\n",
        "        with model.hooks(fwd_hooks=fwd_hooks_clean, bwd_hooks=bwd_hooks):\n",
        "            logits = model(clean)\n",
        "            label = torch.tensor(0, device=device, dtype=model.cfg.dtype)\n",
        "            metric_value = metric(sentence,logits)\n",
        "            metric_value.backward()\n",
        "\n",
        "    scores /= total_items\n",
        "\n",
        "    return scores\n",
        "\n",
        "def get_scores_ig(model: HookedTransformer, graph: Graph, dataset, metric: Callable[[Tensor], Tensor], steps=30):\n",
        "    scores = torch.zeros((graph.n_forward, graph.n_backward), device=device, dtype=model.cfg.dtype)\n",
        "\n",
        "    total_items = 0\n",
        "    for sentence, corrupted in tqdm(dataset):\n",
        "        sens = [sentence, corrupted]\n",
        "        sens = [str(s) for s in sens]\n",
        "        max_length = max(len(model.tokenizer.tokenize(s)) for s in sens)\n",
        "        padded_sentences = [model.tokenizer.encode(s, padding='max_length', max_length=max_length, return_tensors='pt', add_special_tokens=True) for s in sens]\n",
        "        s1 = padded_sentences[0]\n",
        "        s2 = padded_sentences[1]\n",
        "        clean = model.tokenizer.decode(s1[0])\n",
        "        corrupted_dash = model.tokenizer.decode(s2[0])\n",
        "\n",
        "        batch_size = len(clean)\n",
        "        total_items += batch_size\n",
        "        n_pos, input_lengths = get_npos_input_lengths(model, clean)\n",
        "\n",
        "        (fwd_hooks_corrupted, fwd_hooks_clean, bwd_hooks), activation_difference = make_hooks_and_matrices(model, graph, batch_size, n_pos, scores)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            with model.hooks(fwd_hooks=fwd_hooks_corrupted):\n",
        "                _ = model(corrupted_dash)\n",
        "\n",
        "            input_activations_corrupted = activation_difference[:, :, graph.forward_index(graph.nodes['input'])].clone()\n",
        "\n",
        "            with model.hooks(fwd_hooks=fwd_hooks_clean):\n",
        "                clean_logits = model(clean)\n",
        "\n",
        "            input_activations_clean = input_activations_corrupted - activation_difference[:, :, graph.forward_index(graph.nodes['input'])]\n",
        "\n",
        "        def input_interpolation_hook(k: int):\n",
        "            def hook_fn(activations, hook):\n",
        "                new_input = input_activations_clean + (k / steps) * (input_activations_corrupted - input_activations_clean)\n",
        "                new_input.requires_grad = True\n",
        "                return new_input\n",
        "            return hook_fn\n",
        "\n",
        "        total_steps = 0\n",
        "        for step in range(1, steps+1):\n",
        "            total_steps += 1\n",
        "            with model.hooks(fwd_hooks=[(graph.nodes['input'].out_hook, input_interpolation_hook(step))], bwd_hooks=bwd_hooks):\n",
        "                logits = model(clean)\n",
        "                label = torch.tensor(0, device=device, dtype=model.cfg.dtype)\n",
        "                metric_value = metric(sentence,logits)\n",
        "                metric_value.backward()\n",
        "\n",
        "    scores /= total_items\n",
        "    scores /= total_steps\n",
        "\n",
        "    return scores\n",
        "\n",
        "allowed_aggregations = {'sum', 'mean', 'l2'}\n",
        "\n",
        "### Done upto here #########\n",
        "\n",
        "\n",
        "def attribute(model: HookedTransformer, graph: Graph, dataset, metric: Callable[[Tensor], Tensor], aggregation='sum', integrated_gradients: Optional[int]=None):\n",
        "    if aggregation not in allowed_aggregations:\n",
        "        raise ValueError(f'aggregation must be in {allowed_aggregations}, but got {aggregation}')\n",
        "\n",
        "\n",
        "    if integrated_gradients is None:\n",
        "        scores = get_scores(model, graph, dataset, metric)\n",
        "    else:\n",
        "        assert integrated_gradients > 0, f\"integrated_gradients gives positive # steps (m), but got {integrated_gradients}\"\n",
        "        scores = get_scores_ig(model, graph, dataset, metric, steps=integrated_gradients)\n",
        "\n",
        "        if aggregation == 'mean':\n",
        "            scores /= model.cfg.d_model\n",
        "        elif aggregation == 'l2':\n",
        "            scores = torch.linalg.vector_norm(scores, ord=2, dim=-1)\n",
        "\n",
        "    scores = scores.cpu().numpy()\n",
        "\n",
        "    for edge in tqdm(graph.edges.values(), total=len(graph.edges)):\n",
        "        edge.score = scores[graph.forward_index(edge.parent, attn_slice=False), graph.backward_index(edge.child, qkv=edge.qkv, attn_slice=False)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ku-A4jePsSX",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## **EAP and finding best scoring edges for positive Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbVGCb9bPsSY",
        "outputId": "d9d9a43f-ceaf-4cf9-fd6b-2e5ae99b32fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 216/216 [2:29:51<00:00, 41.63s/it]  \n",
            "100%|██████████| 1592881/1592881 [00:03<00:00, 425088.50it/s]\n"
          ]
        }
      ],
      "source": [
        "attribute(model, g, pos_dataset, partial(metric, loss=True, mean=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHXWcC43PsSY"
      },
      "outputs": [],
      "source": [
        "# include all edges whose absolute score is >= the 4th greatest absolute score\n",
        "scores = g.scores(absolute=True)\n",
        "# using a greedy search over the graph, starting from the logits, add in the highest-scoring edges (non-absolute)\n",
        "#g.apply_greedy(2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2z1cdn6PsSY",
        "outputId": "08b6c029-0bf7-4324-cf49-63039cf0ffd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0006, 0.0009, 0.0010])\n"
          ]
        }
      ],
      "source": [
        "print(scores[-3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-T8DHE9PsSY",
        "outputId": "206fdcf2-f0b0-495c-c0f0-8b595611f1a4"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g.apply_greedy(30)\n",
        "g.prune_dead_nodes()\n",
        "gz = g.to_graphviz()\n",
        "gz.draw('llama-dss2-pos.jpg', prog='dot')\n",
        "Image(filename='llama-dss2-pos.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qw9fS5pPsSZ"
      },
      "outputs": [],
      "source": [
        "# Checking the saturation in edge scores\n",
        "No_of_top_scoring_edge_pos = np.arange(0, 1592881, 2849)\n",
        "least_score_saturated_pos = []\n",
        "for num in No_of_top_scoring_edge_pos:\n",
        "  least_score_saturated_pos.append(scores[num])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(least_score_saturated_pos)"
      ],
      "metadata": {
        "id": "W85hf1Lt0QaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCEB5NkAPsSZ",
        "outputId": "01dc543f-f4b9-47e0-ff2d-246eb4aef903"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(No_of_top_scoring_edge_pos, least_score_saturated_pos, marker='o')\n",
        "plt.xlabel('Number of Edges from lowest to highest scoring')\n",
        "plt.ylabel('EAP Score of edges')\n",
        "plt.title('LLAMA-2 (Positive Bias DSS2)')\n",
        "plt.xlim(0)\n",
        "plt.ylim(0)\n",
        "plt.savefig('EAP score distribution for LLAMA2-DSS2-Pos.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP10oBMIPsSZ",
        "outputId": "88d97019-c5cf-4b64-b7d7-550de806309e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge(m31->logits)\n",
            "  Score: 0.0009546387009322643\n",
            "Edge(m30->m31)\n",
            "  Score: 0.0008509331964887679\n",
            "Edge(m30->logits)\n",
            "  Score: 0.0006047217757441103\n",
            "Edge(m30->a31.h11<k>)\n",
            "  Score: 0.0002575383987277746\n",
            "Edge(a24.h14->logits)\n",
            "  Score: 0.0002272905985591933\n",
            "Edge(a31.h10->m31)\n",
            "  Score: 0.0002093672228511423\n",
            "Edge(a31.h10->logits)\n",
            "  Score: 0.00019524118397384882\n",
            "Edge(m18->a24.h14<q>)\n",
            "  Score: 0.00019412748224567622\n",
            "Edge(m1->m2)\n",
            "  Score: 0.0001931387814693153\n",
            "Edge(m4->m5)\n",
            "  Score: 0.00017585490422789007\n"
          ]
        }
      ],
      "source": [
        "# Get the remaining edges as a list\n",
        "remaining_edges_pos = list(g.edges.items())\n",
        "\n",
        "# Sort edges by their score (descending order)\n",
        "remaining_edges_pos.sort(key=lambda x: abs(x[1].score), reverse=True)\n",
        "\n",
        "# Print the top 10 edges\n",
        "for i, (edge_id, edge) in enumerate(remaining_edges_pos[:10]):\n",
        "    print(edge)\n",
        "    print(f\"  Score: {abs(edge.score)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN3MyhrBPsSa",
        "outputId": "358c2a44-9f41-4ca9-d0c2-668d76c8b6ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-05 10:11:44--  https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./refs/heads/main/topnedgesllama.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9007 (8.8K) [text/plain]\n",
            "Saving to: ‘topnedgesllama.csv’\n",
            "\n",
            "topnedgesllama.csv  100%[===================>]   8.80K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-10-05 10:11:44 (29.0 MB/s) - ‘topnedgesllama.csv’ saved [9007/9007]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# getting top 3000 edges\n",
        "!wget https://raw.githubusercontent.com/zubair2004/Finding_Nationality-and-Gender-Bias-Circuits-in-LLMs./refs/heads/main/topnedgesllama.csv\n",
        "df_edges = pd.read_csv('topnedgesllama.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko9BOqRyPsSa"
      },
      "outputs": [],
      "source": [
        "top3000_edges_pos_llama=[]\n",
        "for i, (edge_id,edge) in enumerate(remaining_edges_pos[:3000]):\n",
        "  top3000_edges_pos_llama.append(str(edge_id))\n",
        "df_edges['llama_dss2_pos'] = top3000_edges_pos_llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GWdjxAUPsSa"
      },
      "source": [
        "## **EAP and finding best scoring edges for negative Dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xes3orWbPsSb",
        "outputId": "fc31c87c-192c-4421-857d-431039522456"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [08:11<00:00, 61.48s/it]\n",
            "100%|██████████| 1592881/1592881 [00:03<00:00, 430911.55it/s]\n"
          ]
        }
      ],
      "source": [
        "attribute(model, g1, neg_dataset, partial(metric, loss=True, mean=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRtH-ggDPsSb"
      },
      "outputs": [],
      "source": [
        "scores = g1.scores(absolute=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFpZsXZbPsSb",
        "outputId": "0f2502ba-f7fa-450b-b4d0-8249e337ebd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "print(scores[-3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3AWmXepPsSc",
        "outputId": "c16c7d3b-e19b-4822-81d0-2b16faf72806"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g1.apply_greedy(30)\n",
        "g1.prune_dead_nodes()\n",
        "gz1 = g1.to_graphviz()\n",
        "gz1.draw('llama-dss2-neg.jpg', prog='dot')\n",
        "Image(filename='llama-dss2-neg.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au9dqTjPPsSc"
      },
      "outputs": [],
      "source": [
        "# Checking the saturation in edge scores\n",
        "No_of_top_scoring_edge_neg = np.arange(0, 1592881, 2849)\n",
        "least_score_saturated_neg = []\n",
        "for num in No_of_top_scoring_edge_neg:\n",
        "  least_score_saturated_neg.append(scores[num])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(least_score_saturated_neg)"
      ],
      "metadata": {
        "id": "HiQGEAUn0Gwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "8rvHlcjKPsSc",
        "outputId": "70828478-928c-48c1-9aa6-d325e30b8199"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAGDCAYAAADgeTwhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArqElEQVR4nO3de7gdZX33//fHAIqAxJbog4AENR6wimIELIp46gNYRX94gGpRqiJVFNt6AFsVa1vrY7WKIoqKSAUsniNFwROeAwRBjmIjYomEEkDOCAS+vz9mtlns7MOEPWsnK7xf17WurJl7Dt+ZvbLXZ9/rXjOpKiRJkiTN3H3WdgGSJEnS+sJwLUmSJPXEcC1JkiT1xHAtSZIk9cRwLUmSJPXEcC1JkiT1xHAtSWtBkhOTvGBt1zGRJE9Lcsm9Zb/DlOTxSX6ytuuQNHsM15LWOUkuS/LsCebvnmTZNOvunqSSvHXc/Pnt/J+Nm79FktuTXDbBtk5P8rsk951mn69IcnaSG5IsS/L/kmwwxfKPB3YAvtZOv7Kt7S3jlluWZPep9t2Hdt+PGJuuqh9W1aOGsJ/Dk9yR5Kb2cXGSfYa534Gf+9g+/zfJyUmeM265pyb5SZLrk1yb5MdJnty2bZTkA+3P46Ykv07y723bfZN8OslvktyY5Jwkew4c03nAdUme1+dxSVp3Ga4lrW9eAVzb/juRTZL8ycD0XwC/Hr9QkvnA04ACnj/NPu8PvAnYAtgZeBbw5imWfy1wfN39Ll7XAm9L8oBp9jXq/rOqNq2qTWnO2eeSPHgW9ju33ecOwLeAryR5JUB7zk8GPgL8EbAV8G7gtnbdw4CFwE7AZsAzgHPatg2Ay4GnA5sD7wBOal8/Y46n+ZlLuhcwXEtabyS5P/Ai4PXAgiQLJ1jsP7h78N4fOG6C5fYHFgPHMnlQB6Cqjmp7XW+vqt/ShKldp1hlT+D74+ZdDPwU+JuJVkhynySHJvlVkmuSnJTkjwba9297T69J8o7B3v8kOyX5aZLrkixP8tEkG7VtP2g38fO2V/alg58QtPv84rhaPpzkiPb55m3P7fIkv03yT0nmTHW+Bs7bqcCNwMPbbd3tk4mB470xyUVJXjjQ9ogk3297mq9O8p8d93llVX0YOBx4X5L7AI9s206sqjur6taqOq3tdQZ4MvCVqrqiGpdV1XHtOjdX1eHtvLuq6mSaP9aeNLDb04FnTfcJiKT1g+Fa0vpkH+Am4AvAqTQBebzPAfsmmZPkMTQ9kWdMsNz+NCH5eOD/rmHv6m7AhRM1JNkE2A6YaGzxO4C/GQzNA94IvICmh/QhwO+AI9ttbg98DHgZsCVND+pWA+veSRPatwCeQtOz/jqAqtqtXWaHtkd5fEg9EdhrrEe9Dc4vAU5o2z8LrAQeATwR+DPg1RMd+6A0ngtsBFw0yWK/ovn0YHOanuTPJdmybXsPcBrwQGBrml7nNfFl4EHAo4BfAncm+WySPZM8cNyyi4G/TfK6JI9LkimO68E0Yf0PP//2D6472n1JWs8ZriWtT15BM+zgTprwt1+SDccts4wm2D67XX61XuskTwW2BU6qqrNpQt5fdCkgyQE0Qwj+bZJF5rb/3ji+oarOpQmMb5tgvdcCf19Vy6rqNpqe1xelGdv9IuDrVfWjqrodeCfNcJax7Z5dVYuramVVXQZ8giakT6uqfgP8jCbYAzwTuKWqFrdBck/gTW0P7lXAvwP7TrHJlyS5DrgZWAT8S1VdN8m+v9D2Ft/Vhv7/phmaAU1Y3RZ4SFX9vqp+1OV4BlzR/vtHVXUD8FSac/ZJYEWSRQN/UL0XeB/NHy9LgN8mWe3TjPa1djzw2ar6xbjmG1n1s5e0HjNcS1ovJNmGZizs8e2srwH3A547weLHAa8E9qPpyR7vFcBpVXV1O31CO48kLxv4ctw3xtXwAuBfgT0H1h3vuvbfzSZpfyfw10n+z7j529KME76uDacX0/RIP5imJ/vysQWr6hbgmoG6Htl+ie/KJDcA/0LTi93VCTTnCpo/MsZ6rbcFNgSWD9T1CZoe4cmcVFVzq+r+NMNB9k8y4XjkdqjLuQPb/pOBut8KBDgzyYVJ/moNjgdW9exfC1BVF1fVK6tq63Y/DwE+1LbdWVVHVtWuNAH5n4Fj2k8+xmq9D82Qo9uBgyfY32as+tlLWo8ZriWtL/6S5nfa15NcCVxKE64nGhryJZrQfWnbM/sHSTamGfbw9DaMXkkzpGKHJDtU1fFjX8irqj0H1tuDptfzeVV1/mRFVtXNND3hj5yk/Rc0QxbePq7pcprQPnfgcb92yMFymqERg8fwxwPrHgX8AlhQVQ9otz3p0IYJfAHYPcnWwAtZFa4vp/nS3xYDNT2gqh7bZaNtL/o3gNWupJFkW5rzeTDwx1U1F7hgrO527PRrquohNL36H8vAFU86eCFwFRMMz2l/BsfShOzxbbdW1ZE0w3K2b2sN8GmaP3T2qao7xh3LQ2iGv6xXlxmUNDHDtaR11YZJ7jfw+MOl7cbNv18bbvanGZf7hIHHPsBzkwwGzbGA+0wmHhv8Apoe4e0HtvMY4IdMHNRJ8kyaHvN9qurMDsd2ClMPy3g3cAB3H0bwceCf29BJknlJ9m7bvgg8L8mftl9UfDd3D8+bATcANyV5NPDX4/b3v8DDJiumqlbQfCnvM8Cvq+ridv5ymmEsH0jygDRfunx4kk5DTtqwvgcTj0/fhGaYxop22QMYCLtJXtyuD03QLZqf23T7fHCSg4F3AYdV1V1JHp3k78a2134Ksh/NWGuSvKn9suXGSTZoh4RsxqorhhxF8xp5XlXdOsFudwe+2w7nkbSeM1xLWledAtw68Di8nb/VuPm30lyZYz5wZNujOfZYBCxl1ZCGP6iqJVX1qwn2+wrgM1X1P4PbAj4KvCwTX7/6HTRfujtlsiEj4xzdbmvC3uOq+jXNEINNBmZ/mGaM8mlJbqQJfju3y18IvAH4PE0v9o00vbJjYe7NNMM5bqTpDR7/pcXDgc+2wy9eMknNJ9CMUz9h3Pz9WfWlxN/RBP0tmdxLx84RcBbwY5o/Bu6mqi4CPkBzBZX/BR7XLjvmycAZ7XYWAYe0520y1yW5GTgf2At4cVUd07bdSHMuz2iXWUzTS/53bfutbS1XAlfTXI1mn6q6tP1j57U0f4RdOfDzf9nAvl9G88eRpHuB3P0yq5Kk2ZDkBJrxx18dwrY3pRnfu2CawKkhS/I44OiqesrarkXS7DBcS9J6IM0dAL9DMxzkAzQ9sTuWv+QlaVY5LESS1g9701xe7gpgAbCvwVqSZp8915IkSVJP7LmWJEmSemK4liRJknoy0SWlRtYWW2xR8+fPX9tlSJIkaT129tlnX11V8yZqW6/C9fz581myZMnaLkOSJEnrsSS/mazNYSGSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPhhquk+yR5JIkS5McOkF7khzRtp+XZMeBtsuSnJ/k3CRLhlmnJEmS1IcNhrXhJHOAI4HnAMuAs5IsqqqLBhbbE1jQPnYGjmr/HfOMqrp6WDVKkiRJfRpmz/VOwNKqurSqbgc+D+w9bpm9geOqsRiYm2TLIdYkSZIkDc0ww/VWwOUD08vaeV2XKeC0JGcnOXCynSQ5MMmSJEtWrFjRQ9mSJEnSPTPMcJ0J5tUaLLNrVe1IM3Tk9Ul2m2gnVXV0VS2sqoXz5s2759VKkiRJMzTMcL0M2GZgemvgiq7LVNXYv1cBX6EZZiJJkiSts4YZrs8CFiTZLslGwL7AonHLLAL2b68asgtwfVUtT7JJks0AkmwC/BlwwRBrlSRJkmZsaFcLqaqVSQ4GTgXmAMdU1YVJDmrbPw6cAuwFLAVuAQ5oV38w8JUkYzWeUFXfHFatkiRJUh9SNX4Y9OhauHBhLVniJbElSZI0PEnOrqqFE7V5h0ZJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSeGa0mSJKknhmtJkiSpJ4ZrSZIkqSdDDddJ9khySZKlSQ6doD1Jjmjbz0uy47j2OUnOSXLyMOuUJEmS+jC0cJ1kDnAksCewPbBfku3HLbYnsKB9HAgcNa79EODiYdUoSZIk9WmYPdc7AUur6tKquh34PLD3uGX2Bo6rxmJgbpItAZJsDTwX+NQQa5QkSZJ6M8xwvRVw+cD0snZe12U+BLwVuGtI9UmSJEm9Gma4zgTzqssySf4cuKqqzp52J8mBSZYkWbJixYp7UqckSZLUi2GG62XANgPTWwNXdFxmV+D5SS6jGU7yzCSfm2gnVXV0VS2sqoXz5s3rq3ZJkiRpjQ0zXJ8FLEiyXZKNgH2BReOWWQTs3141ZBfg+qpaXlWHVdXWVTW/Xe+7VfXyIdYqSZIkzdgGw9pwVa1McjBwKjAHOKaqLkxyUNv+ceAUYC9gKXALcMCw6pEkSZKGLVXjh0GProULF9aSJUvWdhmSJElajyU5u6oWTtTmHRolSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknkwbrpPsmmST9vnLk3wwybbDL02SJEkaLV16ro8CbkmyA/BW4DfAcUOtSpIkSRpBXcL1yqoqYG/gw1X1YWCz4ZYlSZIkjZ4NOixzY5LDgL8EnpZkDrDhcMuSJEmSRk+XnuuXArcBf1VVVwJbAe8falWSJEnSCJo2XLeB+kvAfdtZVwNfGWZRkiRJ0ijqcrWQ1wBfBD7RztoK+OoQa5IkSZJGUpdhIa8HdgVuAKiq/wYeNMyiJEmSpFHUJVzfVlW3j00k2QCo4ZUkSZIkjaYu4fr7Sd4ObJzkOcAXgK8PtyxJkiRp9HQJ14cCK4DzgdcCpwD/MMyiJEmSpFE07XWuq+ou4JPtQ5IkSdIkpg3XSc5n9THW1wNLgH+qqmuGUZgkSZI0arrcofEbwJ3ACe30vu2/NwDHAs/rvyxJkiRp9HQJ17tW1a4D0+cn+XFV7Zrk5cMqTJIkSRo1Xb7QuGmSnccmkuwEbNpOrhxKVZIkSdII6tJz/WrgmCSbAqEZDvLqJJsA7x1mcZIkSdIo6XK1kLOAxyXZHEhVXTfQfNKwCpMkSZJGzaThOsnfTjIfgKr64JBqkiRJkkbSVD3Xm7X/Pgp4MrConX4e8INhFiVJkiSNoknDdVW9GyDJacCOVXVjO304zS3QJUmSJA3ocrWQhwK3D0zfDswfSjWSJEnSCOtytZD/AM5M8hWaOzW+EDhuqFVJkiRJI6jL1UL+Ock3gKe1sw6oqnOGW5YkSZI0eroMCwG4P3BDVX0YWJZkuyHWJEmSJI2kacN1kncBbwMOa2dtCHxumEVJkiRJo6hLz/ULgecDNwNU1RWsukyfJEmSpFaXcH17VRXNlxlpb3suSZIkaZwu4fqkJJ8A5iZ5DfBt4JNdNp5kjySXJFma5NAJ2pPkiLb9vCQ7tvPvl+TMJD9PcmGSd6/JQUmSJElrQ5erhfxbkucAN9DcrfGdVfWt6dZLMgc4EngOsAw4K8miqrpoYLE9gQXtY2fgqPbf24BnVtVNSTYEfpTkG1W1eM0OT5IkSZo9Xa5zTRumpw3U4+wELK2qSwGSfB7YGxgM13sDx7XDThYnmZtky6paDtzULrNh+6g13L8kSZI0q7peiu+e2Aq4fGB6WTuv0zJJ5iQ5F7gK+FZVnTG8UiVJkqSZG2a4zgTzxvc+T7pMVd1ZVU8AtgZ2SvInE+4kOTDJkiRLVqxYMZN6JUmSpBmZNFwn+U777/vu4baXAdsMTG8NXLGmy1TVdcDpwB4T7aSqjq6qhVW1cN68efewVEmSJGnmpuq53jLJ04HnJ3likh0HHx22fRawIMl2STYC9gUWjVtmEbB/e9WQXYDrq2p5knlJ5gIk2Rh4NvCLNT04SZIkaTZN9YXGdwKH0vQmf3BcWwHPnGrDVbUyycHAqcAc4JiqujDJQW37x4FTgL2ApcAtwAHt6lsCn22vOHIf4KSqOnlNDkySJEmabWku1DHFAsk7quo9s1TPjCxcuLCWLFmytsuQJEnSeizJ2VW1cKK2Lte5fk+S5wO7tbNOtxdZkiRJWt20VwtJ8l7gEJrrU18EHNLOkyRJkjSgy01kngs8oaruAkjyWeAc4LBhFiZJkiSNmq7XuZ478HzzIdQhSZIkjbwuPdfvBc5J8j2am77shr3WkiRJ0mq6fKHxxCSnA0+mCddvq6orh12YJEmSNGq69FxTVctZ/QYwkiRJkgZ0HXMtSZIkaRqGa0mSJKknncJ1kqcmOaB9Pi/JdsMtS5IkSRo9XW4i8y7gbay6QsiGwOeGWZQkSZI0irr0XL8QeD5wM0BVXQFsNsyiJEmSpFHUJVzfXlUFFECSTYZbkiRJkjSauoTrk5J8Apib5DXAt4FPDrcsSZIkafRMeZ3rJAH+E3g0cAPwKOCdVfWtWahNkiRJGilThuuqqiRfraonAQZqSZIkaQpdhoUsTvLkoVciSZIkjbgutz9/BnBQkstorhgSmk7txw+zMEmSJGnUdAnXew69CkmSJGk9MO2wkKr6DTAXeF77mNvOkyRJkjSgyx0aDwGOBx7UPj6X5A3DLkySJEkaNV2GhbwK2LmqbgZI8j7gp8BHhlmYJEmSNGq6XC0kwJ0D03e28yRJkiQN6NJz/RngjCRfaadfAHx6aBVJkiRJI2racF1VH0xyOvBUmh7rA6rqnGEXJkmSJI2aacN1kl2AC6vqZ+30Zkl2rqozhl6dJEmSNEK6jLk+CrhpYPrmdp4kSZKkAZ2+0FhVNTZRVXfRbay2JEmSdK/SJVxfmuSNSTZsH4cAlw67MEmSJGnUdAnXBwF/Cvy2fewMHDjMoiRJkqRR1OVqIVcB+85CLZIkSdJIm7TnOslrkixonyfJMUmuT3Jekh1nr0RJkiRpNEw1LOQQ4LL2+X7ADsDDgL8FPjzcsiRJkqTRM1W4XllVd7TP/xw4rqquqapvA5sMvzRJkiRptEwVru9KsmWS+wHPAr490LbxcMuSJEmSRs9UX2h8J7AEmAMsqqoLAZI8HS/FJ0mSJK1m0nBdVScn2RbYrKp+N9C0BHjp0CuTJEmSRsyUl+KrqpXA78bNu3moFUmSJEkjqstNZCRJkiR1YLiWJEmSejLVTWQelORDSU5O8t4kD5jNwiRJkqRRM1XP9XHAzcBHgE2BI2alIkmSJGlETfWFxv9TVX/fPj81yc9moyBJkiRpVE0VrpPkgUDa6TmD01V17bCLkyRJkkbJVOF6c+BsVoVrgLHe6wIeNqyiJEmSpFE01U1k5s9iHZIkSdLIW6NL8SV5eJK/T3LBsAqSJEmSRtW04TrJlknelORM4EKa3u79hl6ZJEmSNGKmus71a5J8F/g+sAXwamB5Vb27qs6frQIlSZKkUTHVFxqPBH4K/EVVLQFIUrNSlSRJkjSCpgrXDwFeDHwwyYOBk4ANZ6UqSZIkaQRNOiykqq6uqqOqajfgWcD1wFVJLk7yL102nmSPJJckWZrk0Anak+SItv28JDu287dJ8r12XxcmOeQeHp8kSZI0azpdLaSqllXVv1XVk4AXAL+fbp0kc2iGluwJbA/sl2T7cYvtCSxoHwcCR7XzVwJ/V1WPAXYBXj/BupIkSdI6ZaovNL514PmLx55X1SXA/TpseydgaVVdWlW3A58H9h63zN7AcdVYDMxNsmVVLa+qn7X7uxG4GNiq60FJkiRJa8NUPdf7Djw/bFzbHh22vRVw+cD0MlYPyNMuk2Q+8ETgjIl2kuTAJEuSLFmxYkWHsiRJkqThmCpcZ5LnE01Pt/6Y8VcbmXKZJJsCXwLeVFU3TLSTqjq6qhZW1cJ58+Z1KEuSJEkajqnCdU3yfKLpiSwDthmY3hq4ousySTakCdbHV9WXO+xPkiRJWqumCtc7JLkhyY3A49vnY9OP67Dts4AFSbZLshHNMJNF45ZZBOzfXjVkF+D6qlqeJMCngYur6oNrfliSJEnS7Jv0OtdVNWcmG66qlUkOBk4F5gDHVNWFSQ5q2z8OnALsBSwFbgEOaFffFfhL4Pwk57bz3l5Vp8ykJkmSJGmYUrX+3HRx4cKFtWTJkrVdhiRJktZjSc6uqoUTtXW6zrUkSZKk6RmuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4YriVJkqSeGK4lSZKknhiuJUmSpJ4MNVwn2SPJJUmWJjl0gvYkOaJtPy/JjgNtxyS5KskFw6xRkiRJ6svQwnWSOcCRwJ7A9sB+SbYft9iewIL2cSBw1EDbscAew6pPkiRJ6tswe653ApZW1aVVdTvweWDvccvsDRxXjcXA3CRbAlTVD4Brh1ifJEmS1KthhuutgMsHppe189Z0mSklOTDJkiRLVqxYcY8KlSRJkvowzHCdCebVPVhmSlV1dFUtrKqF8+bNW5NVJUmSpF4NM1wvA7YZmN4auOIeLCNJkiSNhGGG67OABUm2S7IRsC+waNwyi4D926uG7AJcX1XLh1iTJEmSNDRDC9dVtRI4GDgVuBg4qaouTHJQkoPaxU4BLgWWAp8EXje2fpITgZ8Cj0qyLMmrhlWrJEmS1IdUrdEQ53XawoULa8mSJWu7DEmSJK3HkpxdVQsnavMOjZIkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElSTwzXkiRJUk8M15IkSVJPDNeSJElST4YarpPskeSSJEuTHDpBe5Ic0bafl2THrutKkiRJ65oNhrXhJHOAI4HnAMuAs5IsqqqLBhbbE1jQPnYGjgJ27rjuas7/7fXMP/S/+j8YSZIkrVMeeP8NedfzHssLnrjV2i7lbobZc70TsLSqLq2q24HPA3uPW2Zv4LhqLAbmJtmy47qSJEm6l/rdLXfwli/+nK+e89u1XcrdDDNcbwVcPjC9rJ3XZZku60qSJOle7I47i/efesnaLuNuhjYsBMgE86rjMl3WbTaQHAgcCHCfjR/A8s++aQ1KlCRJ0ihbXpDDlp49y7vddrKGYYbrZcA2A9NbA1d0XGajDusCUFVHA0cDJFly2y3XL5xZ2fdeSZZUlefvHvL8zYznb2Y8fzPj+ZsZz9/MeP5mZl07f8McFnIWsCDJdkk2AvYFFo1bZhGwf3vVkF2A66tqecd1JUmSpHXK0Hquq2plkoOBU4E5wDFVdWGSg9r2jwOnAHsBS4FbgAOmWndYtUqSJEl9GOawEKrqFJoAPTjv4wPPC3h913U7OHpNa9TdeP5mxvM3M56/mfH8zYznb2Y8fzPj+ZuZder8pcm3kiRJkmbK259LkiRJPRm5cD2TW6qr0/l7WXvezkvykyQ7rI0611XTnb+B5Z6c5M4kL5rN+tZ1Xc5fkt2TnJvkwiTfn+0a13Ud/g9vnuTrSX7ensMD1kad66IkxyS5KskFk7T7/jGFDufP948pTHf+Bpbz/WMCXc7fOvP+UVUj86D5cuOvgIfRXK7v58D245bZC/gGzbWydwHOWNt1ryuPjufvT4EHts/39Pyt2fkbWO67NN8ZeNHarntdeXR8/c0FLgIe2k4/aG3XvS49Op7DtwPva5/PA64FNlrbta8LD2A3YEfggknaff+Y2fnz/WMG569dxvePe3j+1qX3j1HruZ7JLdXV4fxV1U+q6nft5GKaa4yr0eX1B/AG4EvAVbNZ3Ajocv7+AvhyVf0PQFV5Du+uyzksYLMkATalCdcrZ7fMdVNV/YDmfEzG948pTHf+fP+YWofXH/j+MakO52+def8YtXA9k1uqa83PzatoenHUmPb8JdkKeCHwcTRel9ffI4EHJjk9ydlJ9p+16kZDl3P4UeAxNDfeOh84pKrump3yRp7vH/3x/WMN+f4xY+vM+8dQL8U3BDO5pbrW7Lbyz6D55fjUoVY0Wrqcvw8Bb6uqO5uOQw3ocv42AJ4EPAvYGPhpksVV9cthFzciupzD/wucCzwTeDjwrSQ/rKobhlzb+sD3jx74/nGPfQjfP2ZinXn/GLVwPZNbqqvjuUnyeOBTwJ5Vdc0s1TYKupy/hcDn21+MWwB7JVlZVV+dlQrXbV3//15dVTcDNyf5AbADYLhudDmHBwD/Ws2gw6VJfg08Gjhzdkocab5/zJDvHzPi+8fMrDPvH6M2LGQmt1RXh/OX5KHAl4G/tLdwNdOev6rarqrmV9V84IvA6/zF+Add/v9+DXhakg2S3B/YGbh4lutcl3U5h/9D03NDkgcDjwIundUqR5fvHzPg+8fM+P4xY+vM+8dI9VzXDG6prs7n753AHwMfa/96XllVC9dWzeuSjudPk+hy/qrq4iTfBM4D7gI+VVVTXrbq3qTja/A9wLFJzqcZ5vC2qrp6rRW9DklyIrA7sEWSZcC7gA3B948uOpw/3z+m0OH8aQrTnb916f3DOzRKkiRJPRm1YSGSJEnSOstwLUmSJPXEcC1JkiT1xHAtSZIk9cRwLUmSpHuFJMckuSpJpyuJJHlJkouSXJjkhC7rGK4lTStJJfnAwPSbkxze07aPTfKiPrY1zX5enOTiJN8bN39+kluTnDvwWO22uUlemeSjQ6zv0e2+z0ny8CHuZ6jHMcH+5iZ53Zq2TbG9+ZO9KSb5xyTPnmb9w5O8eU32Ocl2XpnkITPdzhrs71NJtp+t/UnrsWOBPbosmGQBcBiwa1U9FnhTl/UM15K6uA34/5JssbYLGZRkzhos/iqamzI8Y4K2X1XVEwYex/VU4pp4AfC1qnpiVf1qbGZ7Q5NR/l09F5gsQE/Vtsaq6p1V9e2+tjeNVwKzEq6TzKmqV1fVRbOxP2l9VlU/AK4dnJfk4Um+meTsJD9M8ui26TXAkVX1u3bdq7rsY5R/YUuaPSuBo4G/Gd8wvuc5yU3tv7sn+X6Sk5L8Msm/JnlZkjOTnD+ud/bZ7S+0Xyb583b9OUnen+SsJOclee3Adr/Xfjx3/gT17Ndu/4Ik72vnvRN4KvDxJO/vetBJDmhr+j6w68D8hydZ3Nb2j2PH3La9ZaDmd7fzNknyX0l+3tb10nH72YumR+TV7bHNb3vZPwb8DNimPRcXtMf20ntwjic6vm2TfKet9TtJHtqe90vbUD83yV1JdmuX/2GSR7THc0x7nOck2bttf2y773PbbS4A/hV4eDtv/Lm/W1u7z9WOcwJzknwyzce0pyXZuN3/H16LSfZK8oskP0pyRJKTB9bfPsnp7XG+ceB8vHyg/k+052JOu92xmv6m3cdC4Ph22Y3Hndc3pvkY+bwkn2/nbZrkM+02zkuyTzt/tddrO/+m9rV1BvCUtt6FA23/3L6eFqe5E+eUr0tJUzoaeENVPQl4M/Cxdv4jgUcm+XH7f6tTjzdV5cOHDx9TPoCbgAcAlwGbt798Dm/bjgVeNLhs++/uwHXAlsB9gd8C727bDgE+NLD+N2n+2F8ALAPuBxwI/EO7zH2BJcB27XZvBraboM6H0Nz+ex7NHWi/C7ygbTsdWDjBOvOBW4FzBx5Pa+se29ZGwI+Bj7brnAzs1z4/aOCY/6z9JZ32eE4GdgP2AT45sM/NJ6jjcODNAzXdBezSTu8DfIvmrowPbuvasus5HrefVw4cx9eBV7TP/wr4avv8m8BjgT+nueX637fb/3Xb/i/Ay9vnc4FfApsAHwFe1s7fCNi4PZYLJnld3a1tsuOcYJ2VwBPa6ZMGajkWeBHN6+dy2tcIcCJw8sB5/kl7PFsA19Dc5e0x7fnYsF3uY8D+wJOAbw3sf+5Ur6e27QrgvuOWf9/gzwN4IFO/Xgt4ycDyf9hf2/a89vn/Y9X/kwlflz58+Lj7Y/B3D7Apq78HXNy2nQx8pf0dsR3N+9Pc6bZvz7WkTqrqBuA44I3TLTvgrKpaXlW3Ab8CTmvnn0/zy23MSVV1V1X9N3Ap8GiaoLp/knOBM2huq7ygXf7Mqvr1BPt7MnB6Va2oqpXA8TThdjrjh4X8ENh5YFu3A/85sPxTgC+0zwe/4PJn7eMcmh7nR7c1n0/TO/++JE+rqus71PSbqlrcPn8qcGJV3VlV/wt8vz1W6H6OJ/KUgfr/o90PwA9pzttuwHvb+U+mCdpjx3lo+7M5nSbMPhT4KfD2JG8Dtq2qWzsc56CpjnPQr6vq3Pb52ax+nI8GLh14jZw4rv2/quq2am4LfxVNkH8WTZA+qz2uZwEPo3k9PizJR9peqxs6HMd5NL3aL6f5QwDg2cCRYwtU8zHzVK/XO4EvTbL922ne9OHuxz/Z61LS5O4DXDfuPeAxbdsymuF6d7S/Ty5h1fvQlBuUpK4+RDN2eZOBeStpf5ckCU2P5ZjbBp7fNTB9F01P3Zgat5+i6f19w8Avu+2qaiw43jxJfel4HF2Nr2s6Ad47UPMjqurTVfVLmuB2PvDeNMNUpjN4jFMdV9dz3MXY8f6Qpvd+J+AUmt7p3YEfDNSzz8BxPrSqLq6qE4Dn0/QCnZrkmWu4/64/v8FjvpPVj3O67Uy0foDPDhzTo6rq8DYE70DzR8TrgU91qO+5NEH6ScDZSca2P/71NFWdv6+qOydpu6PabjUmPn5JHbUdR79O8mL4w/dcdmibvwo8o52/Bc0wkUun26bhWlJnVXUtzcfwrxqYfRlNiADYm+bjszX14iT3accIP4ymd+BU4K+TbAiQ5JFJNplqIzQ93E9PskWaLzvuR9P7eU+cAeye5I/bGl480LaYZggDwL4D808F/irJpm3NWyV5UJqrStxSVZ8D/g3YcQ1r+QHw0nb87zya3s0z1/yQVvMTVtX/MuBH7fMzgD8F7qqq39N8TPpamtANzXG+of1jiiRPbP99GE2P8RHAIuDxwI3AZpPsf3xbX8f5C5re5vnt9GRjtwd9B3hRkgcBJPmjNGPStwDuU1VfAt7Bqp/dhMeV5sun21TV94C30vxhsinNJwoHDyz3QPp9vcLkr0tJrSQn0nzK9qgky5K8iub336uS/By4kOa9DJrfddckuQj4HvCWqrpmun34166kNfUBBkIC8Enga0nOpAkok/UqT+USmlDxYOCgqvp9kk/RfNz9szbEraC5osakqmp5ksNofgkGOKWqvtZh/w9vhwKMOaaqjkhzucGfAstphnmMXZ3kTcDnkvwd8F/A9e3+T0vyGOCnbe68CXg58Ajg/UnuAu4A/rpDTYO+QvOR/89pej/fWlVXZtU32u+pNwLHJHkLzfk9oD2O25JcThPWoAnV+7HqC6TvofkU47z2Z3MZzfjslwIvT3IHcCXwj1V1bftloAuAb1TVW8Z2XlXXDLbRhNHVjnNND6qqbk1zib9vJrmaDgG9qi5K8g/AaW1AvoOmp/pW4DNZdcWWw9p/j6X5guytwFMGhsDMoXltbE7zGvz3qrouyT8BR7bHeifN2Pgv38PX62TexASvS0mrVNV+kzSt9mXF9hOiv20fnWXVJ0uSpC6S3B+4taoqyb40XyLbe7r1NHuSbFpVN7Xh/0jgv6vq39d2XcPk61JaN9hzLUlr7knAR9vgdh3NlTa0bnlNklfQfAfgHOATa7me2eDrUloH2HMtSZIk9cQvNEqSJEk9MVxLkiRJPTFcS5IkST0xXEuSJEk9MVxLkiRJPTFcS5IkST35/wGBjmfuZ/t/UgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(No_of_top_scoring_edge_neg, least_score_saturated_neg, marker='o')\n",
        "plt.xlabel('Number of Edges from lowest to highest scoring')\n",
        "plt.ylabel('EAP Score of edges')\n",
        "plt.title('LLAMA-2 (Negative Bias DSS2)')\n",
        "plt.xlim(0)\n",
        "plt.ylim(0)\n",
        "plt.savefig('EAP score distribution for LLAMA2-DSS2-Neg.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(No_of_top_scoring_edge_neg, least_score_saturated_pos, linestyle='dotted', marker='o', color='red',label='Postive Bias')\n",
        "plt.plot(No_of_top_scoring_edge_neg, least_score_saturated_neg, linestyle='dotted', marker='x', color='blue',label='Negative Bias')\n",
        "plt.xlabel('Number of Edges from lowest to highest scoring')\n",
        "plt.ylabel('EAP Score of edges')\n",
        "plt.title('LLAMA-2 DSS2: edge scores')\n",
        "plt.legend(loc='best')\n",
        "plt.xlim(0)\n",
        "plt.ylim(0)\n",
        "plt.savefig('EAP score distribution for LLAMA2-DSS2 (dotted).jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JKNZ7Weh0ZFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(No_of_top_scoring_edge_neg, least_score_saturated_pos, marker='o', color='red',label='Postive Bias')\n",
        "plt.plot(No_of_top_scoring_edge_neg, least_score_saturated_neg, marker='x', color='blue',label='Negative Bias')\n",
        "plt.xlabel('Number of Edges from lowest to highest scoring')\n",
        "plt.ylabel('EAP Score of edges')\n",
        "plt.title('LLAMA-2 DSS2: edge scores')\n",
        "plt.legend(loc='best')\n",
        "plt.xlim(0)\n",
        "plt.ylim(0)\n",
        "plt.savefig('EAP score distribution for LLAMA2-DSS2.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ve92e3H40Y0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6AQriESPsSd",
        "outputId": "da010870-d3a2-4e38-f9b3-c257f202c51a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge(input->a0.h0<q>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h0<k>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h0<v>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h1<q>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h1<k>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h1<v>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h2<q>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h2<k>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h2<v>)\n",
            "  Score: 0.0\n",
            "Edge(input->a0.h3<q>)\n",
            "  Score: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Get the remaining edges as a list\n",
        "remaining_edges_neg = list(g1.edges.items())\n",
        "\n",
        "# Sort edges by their score (descending order)\n",
        "remaining_edges_neg.sort(key=lambda x: abs(x[1].score), reverse=True)\n",
        "\n",
        "# Print the top 10 edges\n",
        "for i, (edge_id, edge) in enumerate(remaining_edges_neg[:10]):\n",
        "    print(edge)\n",
        "    print(f\"  Score: {abs(edge.score)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkD_DBpOPsSd"
      },
      "outputs": [],
      "source": [
        "top3000_edges_neg_llama=[]\n",
        "for i, (edge_id,edge) in enumerate(remaining_edges_neg[:3000]):\n",
        "  top3000_edges_neg_llama.append(str(edge_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6buyXQyPsSd"
      },
      "outputs": [],
      "source": [
        "df_edges['llama_dss2_neg'] = top3000_edges_neg_llama\n",
        "df_edges.to_csv('topnedgesllama.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EZ1axhdxPsSQ",
        "E_dti9v1PsSS",
        "BxENjhKsPsSS",
        "6Z5mQw0CPsSU",
        "__DGxOsLPsSW"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}